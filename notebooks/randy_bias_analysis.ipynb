{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faa93cf8",
   "metadata": {},
   "source": [
    "# May Code Pudding: Bias Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7507d",
   "metadata": {},
   "source": [
    "## Getting Packages and Reading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd0ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, pipeline\n",
    "\n",
    "import openpyxl\n",
    "import xlrd\n",
    "\n",
    "# Just in case\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac723be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\uberb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\uberb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk setup\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b347d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x295db1dfbe0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444a1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(os.pardir, 'datasets')\n",
    "\n",
    "#df_sg1 = pd.read_csv(os.path.join(dataset_path, 'final_labels_SG1.csv'), sep=';')\n",
    "df_sg2 = pd.read_csv(os.path.join(dataset_path, 'final_labels_SG2.csv'), sep=';')\n",
    "#df_mbic = pd.read_csv(os.path.join(dataset_path, 'final_labels_MBIC.csv'), sep=';')\n",
    "\n",
    "df_lex = pd.read_excel(os.path.join(dataset_path, 'bias_word_lexicon.xlsx'))\n",
    "\n",
    "df_bias = pd.read_csv(os.path.join(dataset_path, 'news_headlines_usa_biased.csv'))\n",
    "df_neutral = pd.read_csv(os.path.join(dataset_path, 'news_headlines_usa_neutral.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4597be4",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────T\n",
    "\n",
    "This code loads a collection of datasets that will be used to train and evaluate a model for detecting bias in text.\n",
    "\n",
    "**First**, it sets up the file path to the folder where all the data is stored. The path points one level above the current folder into a directory called `datasets`. This helps keep the project organized and ensures anyone running the code can find the files, no matter where the script is located.\n",
    "\n",
    "**Next**, it loads three labeled datasets named `SG1`, `SG2`, and `MBIC`. These files contain sentences that have already been marked as either biased or non-biased. They use semicolons instead of commas to separate the data, which is why the `sep=';'` setting is used. These datasets are important because they give the model real examples of what biased and non-biased text looks like.\n",
    "\n",
    "**Then**, it reads in a file called `bias_word_lexicon.xlsx`, which is an Excel file containing a list of words commonly linked to bias. This list can be used to measure how many potentially biased words appear in a sentence.\n",
    "\n",
    "**Finally**, it loads two more datasets: one containing biased news headlines and one containing neutral ones. These shorter texts can help the model recognize how bias appears even in small snippets of text.\n",
    "\n",
    "Altogether, this step is about preparing all the raw data the model will need — including examples, labels, and word lists — so that the rest of the project can run smoothly.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "I loaded only the `SG2` dataset and excluded the others from the analysis because they contain duplicate sentences. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a6f378",
   "metadata": {},
   "source": [
    "## Getting Data Merged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee37673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>label_bias</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "      <td>https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>Non-biased</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"</td>\n",
       "      <td>https://www.alternet.org/2020/06/law-and-order-is-a-debased-concept-used-to-cover-up-right-wing-crime-and-depravity-heres-why/</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>gun control</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['bizarre', 'characteristically']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.</td>\n",
       "      <td>https://www.nbcnews.com/news/latino/after-stephen-miller-s-white-nationalist-views-outed-latinos-ask-n1096071</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['criminals', 'fringe', 'extreme']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.</td>\n",
       "      <td>https://www.alternet.org/2019/07/fox-news-has-gone-so-deep-into-white-nationalism-that-donald-trump-now-believes-its-how-hell-win-in-2020/</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>left</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/-vHhfcwC74U/</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>marriage-equality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Biased</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['cult']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                                                                   \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.   \n",
       "1                                                                                                                                                                                            \"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"   \n",
       "2                                                                                                                                                           ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.   \n",
       "3  ...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.   \n",
       "4                                                                                                                                                                     [Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.   \n",
       "\n",
       "                                                                                                                                    news_link  \\\n",
       "0                               https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change   \n",
       "1              https://www.alternet.org/2020/06/law-and-order-is-a-debased-concept-used-to-cover-up-right-wing-crime-and-depravity-heres-why/   \n",
       "2                               https://www.nbcnews.com/news/latino/after-stephen-miller-s-white-nationalist-views-outed-latinos-ask-n1096071   \n",
       "3  https://www.alternet.org/2019/07/fox-news-has-gone-so-deep-into-white-nationalism-that-donald-trump-now-believes-its-how-hell-win-in-2020/   \n",
       "4                                                                                    http://feedproxy.google.com/~r/breitbart/~3/-vHhfcwC74U/   \n",
       "\n",
       "      outlet              topic   type  label_bias  \\\n",
       "0   Fox News        environment  right  Non-biased   \n",
       "1   Alternet        gun control   left      Biased   \n",
       "2      MSNBC  white-nationalism   left      Biased   \n",
       "3   Alternet  white-nationalism   left      Biased   \n",
       "4  Breitbart  marriage-equality    NaN      Biased   \n",
       "\n",
       "                           label_opinion                        biased_words  \n",
       "0                       Entirely factual                                  []  \n",
       "1  Somewhat factual but also opinionated   ['bizarre', 'characteristically']  \n",
       "2             Expresses writer’s opinion  ['criminals', 'fringe', 'extreme']  \n",
       "3  Somewhat factual but also opinionated                                  []  \n",
       "4             Expresses writer’s opinion                            ['cult']  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_sg1.head()\n",
    "df_sg2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99125a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_bias\n",
       "Non-biased      1863\n",
       "Biased          1810\n",
       "No agreement       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_sg1['label_bias'].value_counts()\n",
    "df_sg2['label_bias'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c2c3d9",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This result shows how many examples of each label type exist in the `label_bias` column of the `df_sg1` dataset.\n",
    "\n",
    "**`Non-biased` – 800 rows**  \n",
    "These are sentences that were labeled as clearly *not biased*. They are likely written in a neutral or factual tone.\n",
    "\n",
    "**`Biased` – 746 rows**  \n",
    "These are sentences that were labeled as *biased*. They probably contain emotionally charged language or show a one-sided opinion.\n",
    "\n",
    "**`No agreement` – 154 rows**  \n",
    "These are sentences where the people labeling the data *could not agree* on whether the sentence was biased or not. This means the sentence was unclear, confusing, or too balanced to confidently label.\n",
    "\n",
    "The value counts tell us that the dataset is fairly balanced between biased and non-biased examples, but there's a smaller group of uncertain cases that may need to be removed or handled differently when training a machine learning model.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "`Non-biased` – 1863 rows\n",
    "\n",
    "`Biased` – 1810 rows\n",
    "\n",
    "`No agreement` – 1 row\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a6f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sg1 = df_sg1[df_sg1['label_bias'] != 'No agreement']\n",
    "# df_sg1['label'] = df_sg1['label_bias'].map({'Biased': 1, 'Non-biased': 0})\n",
    "# df_sg1['bias_word_count'] = df_sg1['biased_words'].apply(lambda x: len(eval(x)) if isinstance(x, str) else 0)\n",
    "# df_sg1.drop(columns='label_bias', inplace=True)\n",
    "\n",
    "df_sg2 = df_sg2[df_sg2['label_bias'] != 'No agreement']\n",
    "df_sg2['label'] = df_sg2['label_bias'].map({'Biased': 1, 'Non-biased': 0})\n",
    "df_sg2['bias_word_count'] = df_sg2['biased_words'].apply(lambda x: len(eval(x)) if isinstance(x, str) else 0)\n",
    "df_sg2.drop(columns='label_bias', inplace=True)\n",
    "\n",
    "# df_mbic = df_mbic[df_mbic['label_bias'] != 'No agreement']\n",
    "# df_mbic['label'] = df_mbic['label_bias'].map({'Biased': 1, 'Non-biased': 0})\n",
    "# df_mbic['bias_word_count'] = df_mbic['biased_words'].apply(lambda x: len(eval(x)) if isinstance(x, str) else 0)\n",
    "# df_mbic.drop(columns='label_bias', inplace=True)\n",
    "\n",
    "# keep_cols = ['text', 'label', 'bias_word_count', 'biased_words']\n",
    "# df_mbic = df_mbic[keep_cols]\n",
    "\n",
    "# combined_df = pd.concat([df_sg1, df_sg2, df_mbic], ignore_index=True)\n",
    "\n",
    "combined_df = df_sg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b22eb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    1863\n",
       "1    1810\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aff0cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_words_set = set(df_lex.iloc[:, 0].str.lower().dropna())\n",
    "\n",
    "combined_df['lexicon_match_count'] = combined_df['text'].apply(\n",
    "    lambda x: sum(word in bias_words_set for word in str(x).lower().split())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d80a7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias['label'] = 1\n",
    "df_neutral['label'] = 0\n",
    "headline_full = pd.concat([df_bias, df_neutral], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.merge(headline_full[['url', 'title']], left_on='news_link', right_on='url', how='left')\n",
    "\n",
    "combined_df['combined_text'] = combined_df.apply(\n",
    "    lambda row: f\"{row['title']}. {row['text']}\" if pd.notnull(row['title']) else row['text'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "combined_df.drop(columns=['url', 'title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885def4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['combined_text'] = combined_df.apply(\n",
    "    lambda row: row['combined_text'] if row['combined_text'] != row['text']\n",
    "    else f\"[NO_TITLE] {row['text']}\",\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec3b0a",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "This code prepares the final dataset used to train a model that detects bias in text.\n",
    "\n",
    "First, it **removes rows** from all three labeled datasets where the label was `\"No agreement\"`, since these examples are unclear.\n",
    "\n",
    "It then **creates a new column called `label`** where:\n",
    "- `\"Biased\"` becomes `1`\n",
    "- `\"Non-biased\"` becomes `0`\n",
    "\n",
    "Next, it counts how many biased words appear in each sentence using the list stored in the `'biased_words'` column, and stores that number in a new column called `bias_word_count`.\n",
    "\n",
    "For the `df_mbic` dataset, only the most important columns are kept: the sentence, label, biased word count, and the list of biased words.\n",
    "\n",
    "All three datasets are then **combined into one**, called `combined_df`.\n",
    "\n",
    "Then, it checks each sentence and counts how many words match the ones in the `bias_word_lexicon.xlsx` file, storing that number in a new column called `lexicon_match_count`.\n",
    "\n",
    "Next, it loads two headline datasets and assigns a label (`1` for biased, `0` for neutral), then combines them.\n",
    "\n",
    "The code tries to **attach each sentence to a headline**, if one exists. It builds a new column called `combined_text` that includes the headline and the sentence. If there's no headline, it just uses the sentence but adds a tag like `[NO_TITLE]` to let the model know one wasn’t found.\n",
    "\n",
    "The final result is a rich dataset where each row has:\n",
    "- A cleaned sentence\n",
    "- A label\n",
    "- Extra features like how many biased words it contains\n",
    "- An optional headline for added context\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "296810a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "      <th>label</th>\n",
       "      <th>bias_word_count</th>\n",
       "      <th>lexicon_match_count</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "      <td>https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NO_TITLE] \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"</td>\n",
       "      <td>https://www.alternet.org/2020/06/law-and-order-is-a-debased-concept-used-to-cover-up-right-wing-crime-and-depravity-heres-why/</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>gun control</td>\n",
       "      <td>left</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>['bizarre', 'characteristically']</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>'Law and order' is a debased concept used to cover up right-wing crime and depravity — here's why. \"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.</td>\n",
       "      <td>https://www.nbcnews.com/news/latino/after-stephen-miller-s-white-nationalist-views-outed-latinos-ask-n1096071</td>\n",
       "      <td>MSNBC</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>left</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['criminals', 'fringe', 'extreme']</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[NO_TITLE] ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.</td>\n",
       "      <td>https://www.alternet.org/2019/07/fox-news-has-gone-so-deep-into-white-nationalism-that-donald-trump-now-believes-its-how-hell-win-in-2020/</td>\n",
       "      <td>Alternet</td>\n",
       "      <td>white-nationalism</td>\n",
       "      <td>left</td>\n",
       "      <td>Somewhat factual but also opinionated</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NO_TITLE] ...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.</td>\n",
       "      <td>http://feedproxy.google.com/~r/breitbart/~3/-vHhfcwC74U/</td>\n",
       "      <td>Breitbart</td>\n",
       "      <td>marriage-equality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expresses writer’s opinion</td>\n",
       "      <td>['cult']</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[NO_TITLE] [Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                                                                   \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.   \n",
       "1                                                                                                                                                                                            \"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"   \n",
       "2                                                                                                                                                           ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.   \n",
       "3  ...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.   \n",
       "4                                                                                                                                                                     [Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.   \n",
       "\n",
       "                                                                                                                                    news_link  \\\n",
       "0                               https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change   \n",
       "1              https://www.alternet.org/2020/06/law-and-order-is-a-debased-concept-used-to-cover-up-right-wing-crime-and-depravity-heres-why/   \n",
       "2                               https://www.nbcnews.com/news/latino/after-stephen-miller-s-white-nationalist-views-outed-latinos-ask-n1096071   \n",
       "3  https://www.alternet.org/2019/07/fox-news-has-gone-so-deep-into-white-nationalism-that-donald-trump-now-believes-its-how-hell-win-in-2020/   \n",
       "4                                                                                    http://feedproxy.google.com/~r/breitbart/~3/-vHhfcwC74U/   \n",
       "\n",
       "      outlet              topic   type                          label_opinion  \\\n",
       "0   Fox News        environment  right                       Entirely factual   \n",
       "1   Alternet        gun control   left  Somewhat factual but also opinionated   \n",
       "2      MSNBC  white-nationalism   left             Expresses writer’s opinion   \n",
       "3   Alternet  white-nationalism   left  Somewhat factual but also opinionated   \n",
       "4  Breitbart  marriage-equality    NaN             Expresses writer’s opinion   \n",
       "\n",
       "                         biased_words  label  bias_word_count  \\\n",
       "0                                  []      0                0   \n",
       "1   ['bizarre', 'characteristically']      1                2   \n",
       "2  ['criminals', 'fringe', 'extreme']      1                3   \n",
       "3                                  []      1                0   \n",
       "4                            ['cult']      1                1   \n",
       "\n",
       "   lexicon_match_count  \\\n",
       "0                    0   \n",
       "1                    2   \n",
       "2                    0   \n",
       "3                    0   \n",
       "4                    0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                 combined_text  \n",
       "0                                                                                                                                                                                   [NO_TITLE] \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.  \n",
       "1                                                                                                    'Law and order' is a debased concept used to cover up right-wing crime and depravity — here's why. \"We have one beautiful law,\" Trump recently said in his characteristically bizarre syntax and diction, repeating the word \"beautiful.\"  \n",
       "2                                                                                                                                                           [NO_TITLE] ...immigrants as criminals and eugenics, all of which were once considered fringe and extreme. White nationalists embrace white supremacist and white separatist views.  \n",
       "3  [NO_TITLE] ...we sounded the alarm in the early months of Trump’s presidency, when prime-time Fox News host Tucker Carlson began to experiment with segments that used euphemisms like “Western civilization” to package the idea that white people are inherently more civilized while people of color are a threat to national stability.  \n",
       "4                                                                                                                                                                     [NO_TITLE] [Black Lives Matter] is essentially a non-falsifiable religious cult that sets itself specifically against Christianity, just like the French Revolution did.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37b6ac",
   "metadata": {},
   "source": [
    "## Getting Merged Data Ready for Modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d99dfbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>news_link</th>\n",
       "      <th>outlet</th>\n",
       "      <th>topic</th>\n",
       "      <th>type</th>\n",
       "      <th>label_opinion</th>\n",
       "      <th>biased_words</th>\n",
       "      <th>label</th>\n",
       "      <th>bias_word_count</th>\n",
       "      <th>lexicon_match_count</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "      <td>https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>environment</td>\n",
       "      <td>right</td>\n",
       "      <td>Entirely factual</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[NO_TITLE] \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              text  \\\n",
       "0  \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.   \n",
       "\n",
       "                                                                                                       news_link  \\\n",
       "0  https://www.foxnews.com/entertainment/australian-actress-yael-stone-giving-up-green-card-fight-climate-change   \n",
       "\n",
       "     outlet        topic   type     label_opinion biased_words  label  \\\n",
       "0  Fox News  environment  right  Entirely factual           []      0   \n",
       "\n",
       "   bias_word_count  lexicon_match_count  \\\n",
       "0                0                    0   \n",
       "\n",
       "                                                                                                                                                combined_text  \n",
       "0  [NO_TITLE] \"Orange Is the New Black\" star Yael Stone is renouncing her U.S. green card to return to her native Australia in order to fight climate change.  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b54e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_df['combined_text']\n",
    "y = combined_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b9b9b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75       559\n",
      "           1       0.75      0.68      0.71       543\n",
      "\n",
      "    accuracy                           0.73      1102\n",
      "   macro avg       0.73      0.73      0.73      1102\n",
      "weighted avg       0.73      0.73      0.73      1102\n",
      "\n",
      "ROC AUC: 0.8039431766143831\n"
     ]
    }
   ],
   "source": [
    "text_feature = 'combined_text'\n",
    "# categorical_features = ['outlet', 'topic', 'type', 'label_opinion']\n",
    "# numeric_features = ['bias_word_count', 'lexicon_match_count']\n",
    "categorical_features = []\n",
    "numeric_features = ['lexicon_match_count']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "classifier = LogisticRegression(max_iter=1000, penalty='l2', C=1.0, solver='liblinear')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', vectorizer, text_feature),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "X = combined_df[[text_feature] + categorical_features + numeric_features]\n",
    "y = combined_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f3e9e0",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This is the initial evaluation of the model's performance using a test set of 2,031 examples.\n",
    "\n",
    "The model is trying to predict whether a sentence is **biased (`1`)** or **non-biased (`0`)**.\n",
    "\n",
    "**For label 0 (non-biased):**\n",
    "- Precision: 0.87 → When the model predicts non-biased, it is correct 87% of the time.\n",
    "- Recall: 0.89 → It correctly finds 89% of the actual non-biased sentences.\n",
    "- F1-score: 0.88 → A balanced measure of both precision and recall.\n",
    "\n",
    "**For label 1 (biased):**\n",
    "- Precision: 0.90 → When the model predicts bias, it is correct 90% of the time.\n",
    "- Recall: 0.88 → It correctly detects 88% of the truly biased sentences.\n",
    "- F1-score: 0.89 → Again, a strong balance.\n",
    "\n",
    "**Overall accuracy**: 89% of all predictions were correct.\n",
    "\n",
    "**ROC AUC: 0.9508**  \n",
    "This is a measure of how well the model separates the two classes. A perfect model scores 1.0, and random guessing is 0.5.  \n",
    "A score of **0.95** means the model is *very good* at telling biased and non-biased sentences apart.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "I removed `bias_word_count` feature and all four categorical features (`outlet`, `topic`, `type`, `label_opinion`) because they will not be available for the scraped Wikipedia articles. \n",
    "\n",
    "Using only `SG2` but retaining all the features made almost no difference in model performance:\n",
    "\n",
    "- **Overall accuracy**: 89% \n",
    "\n",
    "- **ROC AUC**: 0.9495  \n",
    "\n",
    "Using only `SG2` and removing the features listed above severely decreased model performance:\n",
    "\n",
    "- **Overall accuracy**: 73% \n",
    "\n",
    "- **ROC AUC**: 0.8039\n",
    "\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f87798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC: 0.8129649969891259\n",
      "Best Params: {'classifier__C': 10.0, 'preprocessing__text__max_features': 20000, 'preprocessing__text__ngram_range': (1, 3)}\n",
      "Final Test ROC AUC: 0.798031490231511\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "classifier = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', vectorizer, text_feature),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessing__text__max_features': [5000, 10000, 20000],\n",
    "    'preprocessing__text__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'classifier__C': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "X = combined_df[[text_feature] + categorical_features + numeric_features]\n",
    "y = combined_df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='roc_auc', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best AUC:\", grid_search.best_score_)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "\n",
    "y_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "print(\"Final Test ROC AUC:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9b4fe6",
   "metadata": {},
   "source": [
    "## Data Scraping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13ec643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia-api in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (from wikipedia-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (from requests->wikipedia-api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (from requests->wikipedia-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (from requests->wikipedia-api) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\uberb\\anaconda3\\envs\\codepudding\\lib\\site-packages (from requests->wikipedia-api) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install wikipedia-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed92d1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='en',\n",
    "    user_agent='BiasDetectionProject/1.0 (betaknight@yourdomain.com)'\n",
    ")\n",
    "\n",
    "def fetch_article(title):\n",
    "    page = wiki.page(title)\n",
    "    if page.exists():\n",
    "        return page.text\n",
    "    else:\n",
    "        raise ValueError(f\"Article '{title}' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ab8a4",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This code lets us pull text from Wikipedia.\n",
    "\n",
    "It sets up a connection to Wikipedia using English and a custom user agent.  \n",
    "The `fetch_article` function takes an article title, grabs the page, and returns its full text if it exists. If not, it shows an error message.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fb81804-5d5a-478d-8204-866e0fd44aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold for Accuracy: 0.48\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimize the threshold\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_test_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0, 1.01, 0.01)\n",
    "accuracies = [accuracy_score(y_test, y_test_proba > t) for t in thresholds]\n",
    "\n",
    "best_threshold = thresholds[np.argmax(accuracies)]\n",
    "print(f\"Best threshold for Accuracy: {best_threshold:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, accuracies, label='Accuracy')\n",
    "plt.axvline(best_threshold, color='red', linestyle='--', label=f'Best Threshold = {best_threshold:.2f}')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy by Classification Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14300117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    return re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "def predict_bias_from_article(title, model):\n",
    "    article_text = fetch_article(title)\n",
    "    # sentences = sent_tokenize(article_text)\n",
    "    sentences = sent_tokenize(normalize_text(article_text))\n",
    "\n",
    "    temp_df = pd.DataFrame({'combined_text': sentences})\n",
    "\n",
    "    temp_df['lexicon_match_count'] = temp_df['combined_text'].apply(lambda x: sum(word in bias_words_set for word in str(x).lower().split()))\n",
    "    # temp_df['bias_word_count'] = 0\n",
    "    # temp_df['lexicon_match_count'] = 0\n",
    "    # temp_df['outlet'] = 'usa-today'\n",
    "    # temp_df['topic'] = 'politics'\n",
    "    # temp_df['type'] = 'center'\n",
    "    # temp_df['label_opinion'] = 'Somewhat factual but also opinionated'\n",
    "\n",
    "    preds = model.predict(temp_df)\n",
    "    proba = model.predict_proba(temp_df)[:, 1]\n",
    "    # preds = (proba > 0.33).astype(int)\n",
    "    preds = (proba > best_threshold).astype(int)\n",
    "    bias_score = preds.sum() / len(preds)\n",
    "\n",
    "    return {\n",
    "        'bias_score': round(bias_score, 3),\n",
    "        'biased_sentences': int(preds.sum()),\n",
    "        'total_sentences': len(sentences),\n",
    "        'sentences': sentences,\n",
    "        'predictions': preds,\n",
    "        'probabilities': proba\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0dae7c",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This function checks how biased a Wikipedia article is.\n",
    "\n",
    "It fetches the article, splits it into sentences, and creates a DataFrame.  \n",
    "Some default values are added to match what the model was trained on.  \n",
    "It then uses the model to predict how biased each sentence is, using a custom threshold of `0.33`.  \n",
    "It returns the bias score (percent of biased sentences), the sentence predictions, and their probabilities.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "I ran an analysis to optimize the threshold for accuracy and found the best value to be `0.48`, so that is what the function uses.\n",
    "\n",
    "I added a `normalize_text` function to trim white space.\n",
    "\n",
    "I removed the hardcoded features (`bias_word_count`, `outlet`, `topic`, `type`, and `label_opinion`) that contribute nothing to the model and computed the `lexicon_match_count` for each article. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a0aa5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=20000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  stop_words=&#x27;english&#x27;),\n",
       "                                                  &#x27;combined_text&#x27;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  []),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;lexicon_match_count&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=20000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  stop_words=&#x27;english&#x27;),\n",
       "                                                  &#x27;combined_text&#x27;),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  []),\n",
       "                                                 (&#x27;num&#x27;, StandardScaler(),\n",
       "                                                  [&#x27;lexicon_match_count&#x27;])])),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>preprocessing: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessing: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                 TfidfVectorizer(max_features=20000,\n",
       "                                                 ngram_range=(1, 3),\n",
       "                                                 stop_words=&#x27;english&#x27;),\n",
       "                                 &#x27;combined_text&#x27;),\n",
       "                                (&#x27;cat&#x27;, OneHotEncoder(handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 []),\n",
       "                                (&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;lexicon_match_count&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>text</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>combined_text</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer(max_features=20000, ngram_range=(1, 3), stop_words=&#x27;english&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>cat</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>num</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;lexicon_match_count&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('text',\n",
       "                                                  TfidfVectorizer(max_features=20000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  stop_words='english'),\n",
       "                                                  'combined_text'),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  []),\n",
       "                                                 ('num', StandardScaler(),\n",
       "                                                  ['lexicon_match_count'])])),\n",
       "                ('classifier',\n",
       "                 LogisticRegression(max_iter=1000, solver='liblinear'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding based on recent best results\n",
    "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1, 3), stop_words='english')\n",
    "classifier = LogisticRegression(max_iter=1000, solver='liblinear', C=1.0)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', vectorizer, text_feature),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ('num', StandardScaler(), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "X = combined_df[[text_feature] + categorical_features + numeric_features]\n",
    "y = combined_df['label']\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7bcca",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This code rebuilds and trains the final machine learning pipeline.\n",
    "\n",
    "It uses `TfidfVectorizer` to turn text into numbers, looking at up to 3-word phrases and limiting to 20,000 features.  \n",
    "It one-hot encodes categories like outlet and topic, and standardizes numeric columns.  \n",
    "All features are combined and passed into a logistic regression model.  \n",
    "The full pipeline is then trained using the labeled dataset.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dc48efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias Score: 0.452 (252 of 557 sentences)\n"
     ]
    }
   ],
   "source": [
    "results = predict_bias_from_article(\"Donald Trump\", pipeline)\n",
    "\n",
    "print(f\"Bias Score: {results['bias_score']} ({results['biased_sentences']} of {results['total_sentences']} sentences)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b05e5ec",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This runs the bias prediction function on the Wikipedia article for \"Donald Trump\".\n",
    "\n",
    "It prints a final score showing that **63 out of 557 sentences** were predicted as biased,  \n",
    "resulting in a **bias score of 0.113**, or **11.3%** of the article.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "The bias score is now much higher for the \"Donald Trump\" article:\n",
    "\n",
    "- **225 out of 557 sentences** were predicted as biased\n",
    "- **bias score = 0.404**\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80b5bc91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ 0.951: Race relations Trump's comments on the 2017 Unite the Right rally, condemning \"this egregious display of hatred, bigotry and violence on many sides\" and stating that there were \"very fine people on both sides\", were criticized as implying a moral equivalence between the white supremacist demonstrators and the counter-protesters.\n",
      "⚠️ 0.881: He used harsher, more dehumanizing anti-immigrant rhetoric than during his presidency.\n",
      "⚠️ 0.877: Political practice and rhetoric Beginning with his 2016 campaign, Trump's politics and rhetoric led to the creation of a political movement known as Trumpism.\n",
      "⚠️ 0.874: Racist and Islamophobic attitudes are strong indicators of support for Trump.\n",
      "⚠️ 0.85: Link to violence and hate crimes Trump has been identified as a key figure in increasing political violence in the U.S., both for and against him.\n",
      "⚠️ 0.829: Research suggests Trump's rhetoric is associated with an increased incidence of hate crimes, and that he has an emboldening effect on expressing prejudicial attitudes due to his normalization of explicit racial rhetoric.\n",
      "⚠️ 0.804: Trump's rhetoric and actions inflame anger and exacerbate distrust through an \"us\" versus \"them\" narrative.\n",
      "⚠️ 0.802: Numerous defendants investigated or prosecuted for violent acts and hate crimes cited his rhetoric in arguing that they were not culpable or should receive leniency.\n",
      "⚠️ 0.792: External links Archive of Donald Trump's tweets Appearances on C-SPAN Donald Trump at IMDb Donald Trump on the Internet Archive\n",
      "⚠️ 0.774: Trump is the central figure of Trumpism, and his faction is dominant within the Republican Party.\n",
      "⚠️ 0.773: According to an analysis in Political Science Quarterly, Trump made \"explicitly racist and sexist appeals to win over white voters\" during his 2016 presidential campaign.\n",
      "⚠️ 0.771: Trump has a history of belittling women when speaking to the media and on social media.\n",
      "⚠️ 0.767: Many of his comments and actions have been characterized as racist or misogynistic, and he has made false and misleading statements and promoted conspiracy theories to a degree unprecedented in American politics.\n",
      "⚠️ 0.767: In 1995, Trump founded Trump Hotels & Casino Resorts (THCR), which assumed ownership of the Trump Plaza.\n",
      "⚠️ 0.763: His first book, The Art of the Deal (1987), was a New York Times Best Seller, and was credited by The New Yorker with making Trump famous as an \"emblem of the successful tycoon\".\n",
      "⚠️ 0.761: Trump disparaged courts and judges he disagreed with, often in personal terms, and questioned the judiciary's constitutional authority.\n",
      "⚠️ 0.76: Trump was impeached in 2019 for abuse of power and obstruction of Congress, and in 2021 for incitement of insurrection; the Senate acquitted him both times.\n",
      "⚠️ 0.753: Relations between the U.S. and its European allies were strained under Trump.\n",
      "⚠️ 0.753: Several studies and surveys found that racist attitudes fueled his political ascent and were more important than economic factors in determining the allegiance of Trump voters.\n",
      "⚠️ 0.752: Trump bought a third Atlantic City venue in 1988, the Trump Taj Mahal.\n",
      "⚠️ 0.75: Trump has also used anti-communist sentiment in his rhetoric, regularly calling his opponents \"communists\" and \"Marxists\".\n",
      "⚠️ 0.745: In 2011, Trump became the leading proponent of the racist \"birther\" conspiracy theory that Barack Obama, the first black U.S. president, was not born in the United States.\n",
      "⚠️ 0.745: Unlike other former presidents, Trump continued to dominate his party; a 2022 profile in The New York Times described him as a modern party boss.\n",
      "⚠️ 0.74: Demagogue for President: The Rhetorical Genius of Donald Trump.\n",
      "⚠️ 0.724: The meeting, which was televised live, was highly contentious as Trump and Vance berated Zelenskyy.\n",
      "⚠️ 0.719: He made lewd comments, disparaged women's physical appearances, and referred to them using derogatory epithets.\n",
      "⚠️ 0.715: Trump left office on January 20 and was acquitted on February 13.\n",
      "⚠️ 0.711: Trump pushed for an expansion of presidential power under a maximalist interpretation of the unitary executive theory.\n",
      "⚠️ 0.706: The shows remade Trump's image for millions of viewers nationwide.\n",
      "⚠️ 0.691: His political positions are populist, more specifically described as right-wing populist.\n",
      "⚠️ 0.688: Licensing the Trump name The Trump Organization often licensed the Trump name for consumer products and services, including foodstuffs, apparel, learning courses, and home furnishings.\n",
      "⚠️ 0.678: During the campaign, Trump made increasingly violent and authoritarian statements.\n",
      "⚠️ 0.676: COVID-19 pandemic Trump initially ignored public health warnings and calls for action from health officials within his administration.\n",
      "⚠️ 0.67: He helped bring far-right fringe ideas and organizations into the mainstream.\n",
      "⚠️ 0.667: Trump's campaign focused on crime, claiming that cities would descend into lawlessness if Democratic nominee Joe Biden won.\n",
      "⚠️ 0.664: Racial and gender views Many of Trump's comments and actions have been characterized as racist.\n",
      "⚠️ 0.663: He pledged to deport millions of illegal immigrants residing in the U.S., and criticized birthright citizenship for incentivizing \"anchor babies\".\n",
      "⚠️ 0.663: During the attack, Trump posted on social media but did not ask the rioters to disperse.\n",
      "⚠️ 0.663: In October 2016, portions of Trump's state filings for 1995 were leaked to a reporter from The New York Times.\n",
      "⚠️ 0.661: The event has been described as an attempted self-coup by Trump.\n",
      "⚠️ 0.66: Domestically, in his first term Trump had chiefly partisan support: 88 percent among Republicans and 7 percent among Democrats.\n",
      "⚠️ 0.654: Foreign policy, 2025–present Trump's second term foreign policy has been variously described as imperialist, expansionist, isolationist, and autarkist, employing the \"America First\" ideology as its cornerstone.\n",
      "⚠️ 0.654: He renamed the airline Trump Shuttle and operated it until 1992.\n",
      "⚠️ 0.652: The report also detailed potential obstruction of justice by Trump but \"did not draw ultimate conclusions\" and left the decision to charge the laws to Congress.\n",
      "⚠️ 0.652: Personal life Family In 1977, Trump married Czech model Ivana Zelníčková.\n",
      "⚠️ 0.651: He publicly disparaged several of his former top officials.\n",
      "⚠️ 0.651: Early life and education Donald John Trump was born on June 14, 1946, at Jamaica Hospital in the New York City borough of Queens, the fourth child of Fred Trump and Mary Anne MacLeod Trump.\n",
      "⚠️ 0.65: See also List of awards and honors received by Donald Trump Pseudonyms used by Donald Trump Notes References Works cited Books ​​​​​ Journals Further reading Mercieca, Jennifer R. (2020).\n",
      "⚠️ 0.65: Social media Trump's social media presence attracted worldwide attention after he joined Twitter in 2009.\n",
      "⚠️ 0.649: Trump was sued for violating the Domestic and Foreign Emoluments Clauses of the U.S. Constitution, the first time that the clauses had been substantively litigated.\n",
      "⚠️ 0.647: False or misleading statements Trump frequently makes false statements in public remarks to an extent unprecedented in American politics.\n",
      "⚠️ 0.646: Trump then posed with a Bible for a photo-op at the nearby St. John's Episcopal Church, with religious leaders condemning both the treatment of protesters and the photo opportunity itself.\n",
      "⚠️ 0.643: Two days later the House of Representatives voted 240–187, mostly along party lines, to condemn his \"racist comments\".\n",
      "⚠️ 0.638: On DEI and antisemitism grounds, he threatened cultural institutions and sixty universities, and forced law firms to capitulate to his political agenda.\n",
      "⚠️ 0.636: Trump had cameos in many films and television shows from 1985 to 2001.\n",
      "⚠️ 0.635: In 1996, Trump acquired and renovated the mostly vacant 71-story skyscraper at 40 Wall Street, later rebranded as the Trump Building.\n",
      "⚠️ 0.634: The New York Times found that he initially made millions of dollars in such stock transactions, but \"lost most, if not all, of those gains after investors stopped taking his takeover talk seriously\".\n",
      "⚠️ 0.633: The second impeachment came after the January 6 attack, for which the House charged Trump with incitement of insurrection on January 13, 2021.\n",
      "⚠️ 0.633: His remarks were condemned as racist.\n",
      "⚠️ 0.629: He gained support based on his \"outsider\" status and lack of political experience, and was highly critical of media coverage, frequently making claims of media bias.\n",
      "⚠️ 0.627: He was exempted from the draft during the Vietnam War due to a claim of bone spurs in his heels.\n",
      "⚠️ 0.626: In 1973, Cohn helped Trump countersue the U.S. government for $100 million (equivalent to $708 million in 2024) over its charges that Trump's properties had racially discriminatory practices.\n",
      "⚠️ 0.626: A nationwide review by ABC News in May 2020 identified at least 54 criminal cases, from August 2015 to April 2020, in which he was invoked in direct connection with violence or threats of violence mostly by white men and primarily against minorities.\n",
      "⚠️ 0.622: In 2005, Trump cofounded Trump University, a company that sold real estate seminars for up to $35,000.\n",
      "⚠️ 0.622: Trump had four White House chiefs of staff, marginalizing or pushing out several.\n",
      "⚠️ 0.622: Foundation The Donald J. Trump Foundation was a private foundation established in 1988.\n",
      "⚠️ 0.621: Trump also failed to deliver the $1 trillion infrastructure spending plan on which he had campaigned.\n",
      "⚠️ 0.621: Trump was slow to appoint second-tier officials in the executive branch, saying many of the positions are unnecessary.\n",
      "⚠️ 0.62: Close personal aides to Trump quit or were forced out.\n",
      "⚠️ 0.619: The New York Times called his portrayal \"a highly flattering, highly fictionalized version\" of himself.\n",
      "⚠️ 0.619: Three of Trump's 15 original cabinet members left or were forced to resign within his first year.\n",
      "⚠️ 0.619: They had three children: Donald Jr. (b.\n",
      "⚠️ 0.617: As a candidate and as president, he frequently accused the press of bias, calling it the \"fake news media\" and \"the enemy of the people\".\n",
      "⚠️ 0.615: Deportation operations first focused on \"target lists\" of criminals formed prior to Trump's second term.\n",
      "⚠️ 0.615: In 1988, Trump acquired the Plaza Hotel with a loan from a consortium of 16 banks.\n",
      "⚠️ 0.612: The building houses the headquarters of the Trump Corporation and Trump's PAC and was his primary residence until 2019.\n",
      "⚠️ 0.612: Several Trump allies were not eligible for pardons under Justice Department rules, and in other cases the department had opposed clemency.\n",
      "⚠️ 0.609: MAGA supporters were the dominant faction in the Republican Party as of 2024.\n",
      "⚠️ 0.608: He has a strong appeal to evangelical Christian voters and Christian nationalists, and his rallies take on the symbols, rhetoric, and agenda of Christian nationalism.\n",
      "⚠️ 0.606: Analysts for The New York Times described this as an intensification of his \"heads I win; tails you cheated\" rhetorical strategy; the newspaper stated that the claim of a rigged election had become the backbone of the campaign.\n",
      "⚠️ 0.605: Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who is the 47th president of the United States.\n",
      "⚠️ 0.605: His administration aggressively moved against the rights of transgender people and what it termed \"gender ideology\".\n",
      "⚠️ 0.604: He is described as embracing extremism, conspiracy theories such as Q-Anon, and far-right militia movements to a greater extent than any modern American president, and engaging in stochastic terrorism.\n",
      "⚠️ 0.604: Roy Cohn was Trump's fixer, lawyer, and mentor for 13 years in the 1970s and 1980s.\n",
      "⚠️ 0.602: He explicitly and routinely disparages racial, religious, and ethnic minorities, and scholars consistently find that racial animus regarding blacks, immigrants, and Muslims are the best predictors of support for Trump.\n",
      "⚠️ 0.602: The loss of his social media presence diminished his ability to shape events and correlated with a dramatic decrease in the volume of misinformation on Twitter.\n",
      "⚠️ 0.6: Media career Trump has published 19 books under his name, most written or cowritten by ghostwriters.\n",
      "⚠️ 0.6: THCR purchased the Taj Mahal and the Trump Castle in 1996 and went bankrupt in 2004 and 2009, leaving him with 10 percent ownership.\n",
      "⚠️ 0.599: In May, two judges ruled that both Mazars and the banks must comply with the subpoenas; Trump's attorneys appealed.\n",
      "⚠️ 0.595: Relationship with the press Trump sought media attention throughout his career, sustaining a \"love-hate\" relationship with the press.\n",
      "⚠️ 0.594: Trump was a millionaire in inflation-adjusted dollars by age eight.\n",
      "⚠️ 0.594: In response to the COVID-19 pandemic from 2020, he downplayed its severity, contradicted health officials, and signed the CARES Act.\n",
      "⚠️ 0.594: Between terms (2021–2025) Upon leaving the White House, Trump began living at Mar-a-Lago, establishing an office there as provided for by the Former Presidents Act.\n",
      "⚠️ 0.593: Conspiracy theories Since before his first presidency, Trump has promoted numerous conspiracy theories, including Obama \"birtherism\", global warming being a hoax, and alleged Ukrainian interference in U.S. elections.\n",
      "⚠️ 0.593: Business career Real estate Starting in 1968, Trump was employed at his father's real estate company, Trump Management, which owned racially segregated middle-class rental housing in New York City's outer boroughs.\n",
      "⚠️ 0.59: Trump blamed DEI and wokeness for problems in society, and, equating diversity with incompetence, he reversed pro-diversity policies in the federal government.\n",
      "⚠️ 0.588: Trump was a candidate in the 2000 Reform Party presidential primaries for three months before he withdrew in February 2000.\n",
      "⚠️ 0.587: Trump claimed the report exonerated him despite Mueller writing that it did not.\n",
      "⚠️ 0.585: Many of his actions and rhetoric have been described as authoritarian and contributing to democratic backsliding.\n",
      "⚠️ 0.584: He became the president of his family's real estate business in 1971, renamed it the Trump Organization, and began acquiring and building skyscrapers, hotels, casinos, and golf courses.\n",
      "⚠️ 0.579: During the 1980s, more than 70 banks had lent Trump $4 billion.\n",
      "⚠️ 0.579: In 1985, he bought the unopened Atlantic City Hilton Hotel and renamed it Trump Castle.\n",
      "⚠️ 0.579: Conflicts of interest Before being inaugurated, Trump moved his businesses into a revocable trust, rather than a blind trust or equivalent arrangement \"to cleanly sever himself from his business interests\".\n",
      "⚠️ 0.578: Personnel, 2025–present In his second term, Trump selected cabinet members with personal loyalty to him, with the \"focus on loyalty over subject-matter expertise\".\n",
      "⚠️ 0.578: Following his reelection, Trump launched lawsuits and created blacklists against certain media outlets, took over the process run by the White House Correspondents' Association to choose what outlets have access to him.\n",
      "⚠️ 0.577: In 2022, New York filed a civil lawsuit against Trump accusing him of inflating the Trump Organization's value to gain an advantage with lenders and banks; He was found liable and ordered to pay $350 million plus interest.\n",
      "⚠️ 0.576: Trump weakened the toughest U.S. sanctions imposed after the 2014 Russian annexation of Crimea.\n",
      "⚠️ 0.576: In February 2025, Trump and Vice President Vance met with Volodymyr Zelenskyy, the president of Ukraine, in the Oval Office.\n",
      "⚠️ 0.572: Trump's refusal to condemn the white supremacist Proud Boys during a 2020 presidential debate and his comment, \"Proud Boys, stand back and stand by\", were said to have led to increased recruitment for the pro-Trump group.\n",
      "⚠️ 0.571: Then his administration removed asylum applicants who failed to meet requirements, revoked the parole status of migrants who entered the U.S. under CBP One and CHNV humanitarian parole, attempted to remove birthright citizenship, and suspended the Refugee Admissions Program.\n",
      "⚠️ 0.571: In May 2017, he dismissed FBI director James Comey, saying a few days later that he was concerned about Comey's role in the Trump–Russia investigations.\n",
      "⚠️ 0.571: His supporters then formed a mob that broke into the building, disrupting certification and causing the evacuation of Congress.\n",
      "⚠️ 0.57: Trump pleaded not guilty.\n",
      "⚠️ 0.569: Early political aspirations Trump registered as a Republican in 1987; a member of the Independence Party, the New York state affiliate of the Reform Party, in 1999; a Democrat in 2001; a Republican in 2009; unaffiliated in 2011; and a Republican in 2012.\n",
      "⚠️ 0.569: Trump attended the private Kew-Forest School through seventh grade.\n",
      "⚠️ 0.569: In the 2016 campaign, he pledged that Roe v. Wade would be overturned \"automatically\" if he were elected and given the opportunity to appoint two or three anti-abortion justices.\n",
      "⚠️ 0.568: He rated lowest in the leadership characteristics categories for moral authority and administrative skills.\n",
      "⚠️ 0.567: The report found that Russia did interfere in 2016 to favor Trump and that Trump and his campaign welcomed and encouraged the effort, but that the evidence \"did not establish\" that Trump campaign members conspired or coordinated with Russia.\n",
      "⚠️ 0.567: Natural gas expanded under Trump, but coal continued to decline.\n",
      "⚠️ 0.567: To reduce his $900 million of personal debt, he sold the Trump Shuttle airline; his megayacht, the Trump Princess, which had been leased to his casinos and kept docked; and other businesses.\n",
      "⚠️ 0.566: His attacks on courts drew rebukes from observers, including sitting federal judges, concerned about the effect of his statements on the judicial independence and public confidence in the judiciary.\n",
      "⚠️ 0.566: He launched side ventures, many licensing the Trump name, and filed for six business bankruptcies in the 1990s and 2000s.\n",
      "⚠️ 0.565: Bush found the request \"strange and unbelievable\".\n",
      "⚠️ 0.565: Trump acquired his style of politics from professional wrestling—with its staged fights and name-calling.\n",
      "⚠️ 0.565: Trump sought to remake civil society to his preferences by executive order.\n",
      "⚠️ 0.564: He rejects the scientific consensus on climate change.\n",
      "⚠️ 0.562: Trump and his incoming administration helped broker a ceasefire between Israel and Hamas alongside the Biden administration, enacted a day prior to his inauguration.\n",
      "⚠️ 0.561: From 1987 to 2006, Trump gave his foundation $5.4 million which had been spent by the end of 2006.\n",
      "⚠️ 0.56: On November 8, 2016, Trump received 306 pledged electoral votes versus 232 for Clinton.\n",
      "⚠️ 0.559: On January 10, 2025, the judge gave Trump a no-penalty sentence known as an unconditional discharge, saying that punitive requirements would have interfered with presidential immunity.\n",
      "⚠️ 0.559: Trump is the only modern U.S. president to leave office with a smaller workforce than when he took office, by three million people.\n",
      "⚠️ 0.559: Many of his actions attempted to bring historically independent institutions under direct executive branch control in diminished forms.\n",
      "⚠️ 0.558: In his last full day in office, he granted 73 pardons and commuted 70 sentences.\n",
      "⚠️ 0.558: In 1971, his father made him president of the company and he began using the Trump Organization as an umbrella brand.\n",
      "⚠️ 0.558: Helping Trump projects, Cohn was a consigliere whose Mafia connections controlled construction unions.\n",
      "⚠️ 0.558: Even before the results were known on the morning after the election, Trump declared victory.\n",
      "⚠️ 0.557: Many suspicious links between Trump associates and Russian officials were discovered.\n",
      "⚠️ 0.557: He repeatedly refused to say whether he would accept the results if he lost and commit to a peaceful transition of power.\n",
      "⚠️ 0.556: Trump told Russian officials he was unconcerned about Russia's election interference.\n",
      "⚠️ 0.553: His administration rolled back key components of the Obama administration's workplace protections against discrimination of LGBTQ people.\n",
      "⚠️ 0.552: Domestic policy, 2025–present Trump inherited a resilient economy from the Biden administration, with increasing economic growth, low unemployment, and declining inflation.\n",
      "⚠️ 0.552: During the 2024 presidential campaign, he made false attacks against the racial identity of his opponent, Kamala Harris, that were described as reminiscent of the birther conspiracy theory.\n",
      "⚠️ 0.552: In February 2022, TMTG launched Truth Social, a social media platform.\n",
      "⚠️ 0.551: Trump's actions, especially in his second term, have been described as authoritarian and contributing to democratic backsliding.\n",
      "⚠️ 0.551: White nationalist publications and social media praised his remarks, which continued over the following days.\n",
      "⚠️ 0.549: In office, he scaled back the Act's implementation through executive orders.\n",
      "⚠️ 0.549: Until 2018, the media rarely referred to his falsehoods as lies, including when he repeated demonstrably false statements.\n",
      "⚠️ 0.546: The Apprentice and The Celebrity Apprentice Producer Mark Burnett made Trump a television star when he created The Apprentice, which Trump hosted from 2004 to 2015 (including variant The Celebrity Apprentice).\n",
      "⚠️ 0.545: Atlantic City casinos In 1984, Trump opened Harrah's at Trump Plaza, a hotel and casino, with financing and management help from the Holiday Corporation.\n",
      "⚠️ 0.544: The alt-right movement coalesced around and supported his candidacy, due in part to its opposition to multiculturalism and immigration.\n",
      "⚠️ 0.544: CIA director Gina Haspel and Army general Mark Milley, chairman of the Joint Chiefs of Staff, grew concerned that Trump might attempt a coup or military action against China or Iran.\n",
      "⚠️ 0.543: Domestic policy Trump took office at the height of the longest economic expansion in American history, which began in 2009 and continued until February 2020, when the COVID-19 recession began.\n",
      "⚠️ 0.542: Two years later, he transferred to the Wharton School of the University of Pennsylvania, graduating in May 1968 with a Bachelor of Science in economics.\n",
      "⚠️ 0.542: Twitter began attaching fact-checks to tweets in which Trump made false claims in May 2020.\n",
      "⚠️ 0.542: Pardons and commutations During his first term, Trump granted 237 requests for clemency, fewer than all presidents since 1900 with the exception of George H. W. Bush and George W. Bush.\n",
      "⚠️ 0.541: Other misinformation, such as misattributing a rise in crime in England and Wales to the \"spread of radical Islamic terror\", served his domestic political purposes.\n",
      "⚠️ 0.541: He continued fundraising, raising a war chest containing more than twice that of the Republican Party, and profited from fundraisers many Republican candidates held at Mar-a-Lago.\n",
      "⚠️ 0.541: In the weeks after the election, Trump withdrew from public activities.\n",
      "⚠️ 0.539: Trump also increased restrictions on granting permanent residency to immigrants needing public benefits.\n",
      "⚠️ 0.539: In February 2022, he launched social media platform Truth Social where he only attracted a fraction of his Twitter following.\n",
      "⚠️ 0.538: Some of Trump's falsehoods were inconsequential, while others had more far-reaching effects, such as his unproven promotion of antimalarial drugs as a treatment for COVID-19, causing a U.S. shortage of these drugs and panic-buying in Africa and South Asia.\n",
      "⚠️ 0.538: The foundation gave to health- and sports-related charities, conservative groups, and charities that held events at Trump properties.\n",
      "⚠️ 0.537: Trump considered a show business career but instead in 1964 enrolled at Fordham University.\n",
      "⚠️ 0.537: They have one son, Barron (b.\n",
      "⚠️ 0.537: Trump repeatedly sought help to overturn the results, personally pressuring Republican local and state office-holders, Republican legislators, the Justice Department, and Vice President Pence, urging actions such as replacing presidential electors, or that Georgia officials \"find\" votes and announce a \"recalculated\" result.\n",
      "⚠️ 0.536: In his first weeks, several of his actions have ignored or violated federal laws, regulations, and the Constitution according to American legal scholars.\n",
      "⚠️ 0.536: He did not release his tax returns, contrary to the practice of every major candidate since 1976 and his promises in 2014 and 2015 to do so if he ran for office.\n",
      "⚠️ 0.535: In 2021, Trump, who had been a member since 1989, resigned from SAG-AFTRA to avoid a disciplinary hearing regarding the January 6 attack.\n",
      "⚠️ 0.535: In January 1994 the siblings formed Apartment Management Associates and took over the management fees formerly collected by Trump Management.\n",
      "⚠️ 0.533: Immigration As president, Trump described illegal immigration as an \"invasion\" of the United States and drastically escalated immigration enforcement.\n",
      "⚠️ 0.533: In May 2024, Trump was convicted on 34 felony counts of falsifying business records.\n",
      "⚠️ 0.533: Trump established the White House Coronavirus Task Force on January 29.\n",
      "⚠️ 0.531: Starting in the 1990s, Trump appeared 24 times as a guest on the nationally syndicated Howard Stern Show.\n",
      "⚠️ 0.531: He claimed credit for pressuring the government to publish Obama's birth certificate, which he considered fraudulent.\n",
      "⚠️ 0.53: After the 1985 season, the league folded, largely due to his attempt to move to a fall schedule (when it would have competed with the National Football League [NFL] for audience) and trying to force a merger with the NFL by bringing an antitrust suit.\n",
      "⚠️ 0.529: Presenting himself as a political outsider, Trump won the 2016 presidential election against the Democratic Party's nominee, Hillary Clinton.\n",
      "⚠️ 0.527: Trump's last major construction project was the 92-story mixed-use Trump International Hotel and Tower in Chicago which opened in 2008.\n",
      "⚠️ 0.525: Trump's proposed immigration policies were a topic of bitter debate during the 2016 campaign.\n",
      "⚠️ 0.524: He considers exercise a waste of energy because he believes the body is \"like a battery, with a finite amount of energy\", which is depleted by exercise.\n",
      "⚠️ 0.524: Only 25 of them had been vetted by the Justice Department's Office of the Pardon Attorney; the others were granted to people with personal or political connections to him, his family, and his allies, or recommended by celebrities.\n",
      "⚠️ 0.524: As well as inflating rents, the schemes served to transfer assets from Fred Trump to his children and nephew and lower the tax burden.\n",
      "⚠️ 0.523: Trump and Clinton participated in three presidential debates in September and October 2016.\n",
      "⚠️ 0.523: From 2004 to 2015, he hosted the reality television show The Apprentice, bolstering his fame as a billionaire.\n",
      "⚠️ 0.522: In February 2021, he registered a new company, Trump Media & Technology Group (TMTG), for providing \"social networking services\" to U.S. customers.\n",
      "⚠️ 0.522: A member of the Republican Party, he served as the 45th president from 2017 to 2021.\n",
      "⚠️ 0.522: Impeachments Trump was impeached twice by the House of Representatives during his first presidential term, though acquitted by the Senate on both occasions.\n",
      "⚠️ 0.521: Trump did not attend Biden's inauguration on January 20.\n",
      "⚠️ 0.52: His father enrolled him in New York Military Academy, a private boarding school, to complete secondary school.\n",
      "⚠️ 0.52: He engaged in an unprecedented targeting of law firms and lawyers that previously represented positions adverse to himself.\n",
      "⚠️ 0.52: He withdrew from the Paris Agreement, making the U.S. the only nation to not ratify it.\n",
      "⚠️ 0.52: Trump and his Plaza Hotel hosted several boxing matches at the Atlantic City Convention Hall.\n",
      "⚠️ 0.52: His administration took an anti-marijuana position, revoking Obama-era policies that provided protections for states that legalized marijuana.\n",
      "⚠️ 0.519: Born into a wealthy family in the New York City borough of Queens, Trump graduated from the University of Pennsylvania in 1968 with a bachelor's degree in economics.\n",
      "⚠️ 0.519: The Republican Party used his election narrative to justify imposing new voting restrictions in its favor.\n",
      "⚠️ 0.518: Clubs In 1985, Trump acquired the Mar-a-Lago estate in Palm Beach, Florida.\n",
      "⚠️ 0.517: Under the provisions of the restructuring agreement, he gave up half his initial stake and personally guaranteed future performance.\n",
      "⚠️ 0.513: Despite Trump initially blaming Democrats and insisting he could not stop the policy with an executive order, he acceded to public pressure in June 2018 and mandated that migrant families be detained together unless \"there is a concern\" of risk for the child.\n",
      "⚠️ 0.513: Health Trump says he has never drunk alcohol, smoked cigarettes, or used drugs.\n",
      "⚠️ 0.512: border to restrict illegal movement and vowed that Mexico would pay for it.\n",
      "⚠️ 0.51: After Trump fired Comey in May 2017, the FBI opened a second investigation into Trump's personal and business dealings with Russia.\n",
      "⚠️ 0.51: Trump supported many of the policies of Israeli prime minister Benjamin Netanyahu.\n",
      "⚠️ 0.509: Early actions, 2025–present Upon taking office, Trump signed a series of executive orders.\n",
      "⚠️ 0.509: Trump's team announced in December 2016 that the foundation would be dissolved.\n",
      "⚠️ 0.508: His falsehoods are a distinctive part of his political identity and have been described as firehosing.\n",
      "⚠️ 0.508: The Electoral College formalized Biden's victory on December 14.\n",
      "⚠️ 0.507: In the 2016 campaign, he benefited from a record amount of free media coverage.\n",
      "⚠️ 0.507: Trump's 2020 presidential campaign sued The New York Times, The Washington Post, and CNN for defamation in opinion pieces about his stance on Russian election interference.\n",
      "⚠️ 0.507: His harsher rhetoric against his political enemies has been described by some historians and scholars as authoritarian, fascist, and unlike anything a political candidate has ever said in American history.\n",
      "⚠️ 0.506: In his second term's first quarter according to Gallup, Trump's approval rating was 45 percent—somewhat better than his first term, and far below the 60 percent average of other presidents.\n",
      "⚠️ 0.505: Lobbyists, foreign government officials, and Trump donors and allies generated hundreds of millions of dollars for his resorts and hotels.\n",
      "⚠️ 0.504: Much of his focus was on party governance and installing in key posts officials loyal to him.\n",
      "⚠️ 0.504: In particular, his campaign launch speech drew criticism for claiming Mexican immigrants were \"bringing drugs, they're bringing crime, they're rapists\"; in response, NBC fired him from Celebrity Apprentice.\n",
      "⚠️ 0.504: In 1989 and 1990, he lent his name to the Tour de Trump cycling stage race, an attempt to create an American equivalent of European races such as the Tour de France or the Giro d'Italia.\n",
      "⚠️ 0.503: In 2007, he received a star on the Hollywood Walk of Fame for his work as producer of Miss Universe.\n",
      "⚠️ 0.502: After his first term, scholars and historians ranked him as one of the worst presidents in American history.\n",
      "⚠️ 0.501: He aimed to boost the production and exports of fossil fuels.\n",
      "⚠️ 0.501: His rhetoric has been described as using fearmongering and demagogy, and he has said that he believes real power comes from fear.\n",
      "⚠️ 0.5: Second presidency (2025–present) Trump began his second term upon his inauguration on January 20, 2025.\n",
      "⚠️ 0.5: As part of an effort to overturn the results, Trump and his allies filed many legal challenges to the results, which were rejected by at least 86 judges in both state and federal courts for having no factual or legal basis.\n",
      "⚠️ 0.5: During the 2016 campaign, Trump promised to protect funding for Medicare and other social safety-net programs.\n",
      "⚠️ 0.499: His relations with allies were transactional and ranged from indifference to hostility, including threats of annexation.\n",
      "⚠️ 0.499: High-profile cases have underscored Trump's broad interpretation of a unitary executive theory of power, and led to significant conflicts with the federal courts.\n",
      "⚠️ 0.499: Trump began his second presidency by pardoning around 1,500 January 6 rioters and initiating mass layoffs of federal workers.\n",
      "⚠️ 0.498: Media outlets described it as an unprecedented public confrontation between an American president and a foreign head of state.\n",
      "⚠️ 0.498: In 2017, estimation of U.S. leadership declined most among allies.\n",
      "⚠️ 0.496: Side ventures In 1970, Trump invested $70,000 to receive billing as coproducer of a Broadway comedy.\n",
      "⚠️ 0.496: In connection with Trump's efforts to overturn the 2020 election and his involvement in the January 6 attack, in December 2022 the U.S. House committee on the attack recommended criminal charges against him for obstructing an official proceeding, conspiracy to defraud the United States, and inciting or assisting an insurrection.\n",
      "⚠️ 0.496: He sleeps about four or five hours a night.\n",
      "⚠️ 0.496: 2006).\n",
      "⚠️ 0.495: Trump described NATO as \"obsolete\" and espoused views that were described as noninterventionist and protectionist.\n",
      "⚠️ 0.495: After winning the 2024 presidential election against Kamala Harris, Trump was sentenced to a penalty-free discharge, and two felony indictments against him were dismissed.\n",
      "⚠️ 0.495: From 2011 until 2015, he was a guest commentator on Fox & Friends.\n",
      "⚠️ 0.494: He has called golfing his \"primary form of exercise\", but usually does not walk the course.\n",
      "⚠️ 0.494: He criticized NATO allies and privately suggested that the U.S. should withdraw from NATO.\n",
      "⚠️ 0.494: The book was ghostwritten by Tony Schwartz, who is credited as a coauthor.\n",
      "⚠️ 0.493: In December 2023, the Colorado Supreme Court ruled him disqualified for the Colorado Republican primary for his role in inciting the January 6, 2021, attack on Congress.\n",
      "⚠️ 0.492: During the 2000s, Trump licensed his name to residential property developments worldwide, 40 of which were never built.\n",
      "⚠️ 0.492: He threatened, signed executive actions, and ordered investigations into his political opponents, critics, and organizations aligned with the Democratic Party.\n",
      "⚠️ 0.492: It was written by Sean Barbabella, the physician to the president.\n",
      "⚠️ 0.492: Many retired military leaders and defense officials condemned his proposal to use the U.S. military against anti-police-brutality protesters.\n",
      "⚠️ 0.491: Internal documents revealed that employees were instructed to use a hard-sell approach, and former employees testified that Trump University had defrauded or lied to its students.\n",
      "⚠️ 0.491: Trump's victory sparked protests in major U.S. cities.\n",
      "⚠️ 0.49: He characterized the comments as \"locker-room talk\".\n",
      "⚠️ 0.49: Grab 'em by the pussy.\"\n",
      "⚠️ 0.489: He suspended American financial contributions to the World Trade Organization.\n",
      "⚠️ 0.488: He has also been accused of racism for insisting a group of five black and Latino teenagers were guilty of raping a white woman in the 1989 Central Park jogger case, even after they were exonerated in 2002 when the actual rapist confessed and his DNA matched the evidence.\n",
      "⚠️ 0.488: The owners shared the proceeds generated by the markups.\n",
      "⚠️ 0.488: In 2023, Trump was found liable in civil cases for sexual abuse and defamation and for business fraud, and in 2024, he was found guilty of falsifying business records, making him the first U.S. president convicted of a felony.\n",
      "⚠️ 0.487: He and Maples married in 1993 and divorced in 1999.\n",
      "⚠️ 0.487: On July 13, 2024, Trump was shot in the ear in an assassination attempt at a campaign rally in Butler Township, Pennsylvania.\n",
      "⚠️ 0.482: The Institute for Policy Integrity found that 78 percent of his proposals were blocked by courts or did not prevail over litigation.\n",
      "⚠️ 0.48: Investigations After he assumed office, Trump was the subject of increasing Justice Department and congressional scrutiny, with investigations covering his election campaign, transition, and inauguration, actions taken during his presidency, his private businesses, personal taxes, and charitable foundation.\n"
     ]
    }
   ],
   "source": [
    "# for sent, prob in zip(results['sentences'], results['probabilities']):\n",
    "#     if prob > 0.3:\n",
    "for sent, prob in sorted(zip(results['sentences'], results['probabilities']), key=lambda x: x[1], reverse=True):\n",
    "    if prob > best_threshold:\n",
    "        print(f\"⚠️ {round(prob, 3)}: {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc02f9",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "These are the sentences from the \"Donald Trump\" Wikipedia article that the model flagged as biased, using a threshold of **0.33**.\n",
    "\n",
    "Each line shows the **bias probability score** followed by the sentence.  \n",
    "Most sentences are between **0.33 and 0.45**, which means they aren't obviously biased, but may contain **framing, emotionally charged words, or subtle implications** the model picked up on.\n",
    "\n",
    "Examples include:\n",
    "- Highlighting **wealth and privilege** in early life\n",
    "- Mentioning **bankruptcies** and **legal troubles**\n",
    "- Using phrases like `\"racist or misogynistic\"` or `\"promoted conspiracy theories\"`\n",
    "\n",
    "This confirms the model can detect **subtle linguistic bias**, even in an article that follows an encyclopedic style.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "I changed the threshold to `0.48`, which flagged many more sentences with biase scores ranging between **0.48 and 0.95**, but the general analysis probably still applies. \n",
    "\n",
    "I also sorted the sentences by bias to make them easier to evaluate. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf9bca",
   "metadata": {},
   "source": [
    "## Creating Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b59ad7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_wikipedia_articles(titles, model, output_file=\"../scraped_data/wiki_bias_predictions.csv\"):\n",
    "    all_data = []\n",
    "\n",
    "    for title in titles:\n",
    "        try:\n",
    "            text = fetch_article(title)\n",
    "            # sentences = sent_tokenize(text)\n",
    "            sentences = sent_tokenize(normalize_text(text))\n",
    "\n",
    "            temp_df = pd.DataFrame({'combined_text': sentences})\n",
    "            \n",
    "            temp_df['lexicon_match_count'] = temp_df['combined_text'].apply(lambda x: sum(word in bias_words_set for word in str(x).lower().split()))\n",
    "            # temp_df['bias_word_count'] = 0\n",
    "            # temp_df['lexicon_match_count'] = 0\n",
    "            # temp_df['outlet'] = 'usa-today'\n",
    "            # temp_df['topic'] = 'politics'\n",
    "            # temp_df['type'] = 'center'\n",
    "            # temp_df['label_opinion'] = 'Somewhat factual but also opinionated'\n",
    "\n",
    "            preds = model.predict(temp_df)\n",
    "            proba = model.predict_proba(temp_df)[:, 1]\n",
    "\n",
    "            temp_df['bias_prediction'] = preds\n",
    "            temp_df['bias_probability'] = proba\n",
    "            temp_df['article_title'] = title\n",
    "            temp_df['sentence_index'] = temp_df.index\n",
    "\n",
    "            all_data.append(temp_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"error: {title} — {e}\")\n",
    "\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d249a951",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This function takes in a list of Wikipedia article titles and runs **bias prediction** on every sentence from every article.\n",
    "\n",
    "For each title:\n",
    "- It fetches the article and splits it into sentences.\n",
    "- A temporary dataset is created with default metadata (like outlet and topic) to match what the model expects.\n",
    "- The model predicts bias for each sentence and adds the result and the bias probability.\n",
    "- It adds the article name and sentence index for organization.\n",
    "\n",
    "All the sentence results from all articles are combined into one dataset and saved as a single CSV file called `wiki_bias_predictions.csv`.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "I normalized the text, removed the hardcoded features (`bias_word_count`, `outlet`, `topic`, `type`, and `label_opinion`) that contribute nothing to the model, and computed the `lexicon_match_count` for each article.\n",
    "\n",
    "I returned the `final_df` to do some EDA. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e394caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Donald Trump\", \"Joe Biden\", \"Kamala Harris\", \"Barack Obama\", \"Ron DeSantis\", \"Bernie Sanders\", \"Antifa\",\n",
    "    \"Tea Party movement\", \"QAnon\", \"Pro-life\", \"Pro-choice\", \"Abortion in the United States\", \"Gun control\",\n",
    "    \"Second Amendment\", \"Immigration to the United States\", \"Border wall\", \"Transgender rights\", \"LGBT adoption\",\n",
    "    \"Same-sex marriage\", \"Gender identity\", \"Critical race theory\", \"Affirmative action\", \"Fox News\", \"MSNBC\", \"CNN\",\n",
    "    \"Breitbart News\", \"The New York Times\", \"Israeli-Palestinian conflict\", \"Hamas\", \"Ukraine war\",\n",
    "    \"Russian invasion of Ukraine\", \"NATO\", \"Taliban\", \"Evangelicalism\", \"Islamophobia\", \"Christian nationalism\",\n",
    "    \"Religious freedom in the United States\", \"Climate change\", \"COVID-19 pandemic\", \"Vaccine hesitancy\",\n",
    "    \"Misinformation\", \"Flat Earth\", \"Creationism\", \"Police brutality\", \"Black Lives Matter\", \"Stop and frisk\",\n",
    "    \"War on drugs\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2166aa2c",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "We chose a large number of topics to ensure that the final dataset would be rich, diverse, and well-populated.\n",
    "\n",
    "Not every Wikipedia article always works — sometimes a page doesn’t exist, fails to load, or doesn’t contain usable sentence structure.  \n",
    "By including a wide mix of political, social, scientific, and controversial topics, we increase the chances that most will work.  \n",
    "This guarantees that even if some articles are skipped or throw errors, we still end up with a **good-sized, well-balanced dataset** for bias analysis.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "110657a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_sentence_dataset = process_wikipedia_articles(topics, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06f649",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "This line runs the full bias detection process on all the topics in the `topics` list using the trained model `pipeline`.\n",
    "\n",
    "It goes through each article, predicts bias sentence-by-sentence, and saves the results into a single CSV file.  \n",
    "By the end, you'll have one dataset with bias predictions across all the selected Wikipedia topics, ready for further analysis or visualization.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "317270ae-318d-4b3f-a9ab-da69f7e71702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_text</th>\n",
       "      <th>lexicon_match_count</th>\n",
       "      <th>bias_prediction</th>\n",
       "      <th>bias_probability</th>\n",
       "      <th>article_title</th>\n",
       "      <th>sentence_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who is the 47th president of the United States.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.605232</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A member of the Republican Party, he served as the 45th president from 2017 to 2021.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.521672</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Born into a wealthy family in the New York City borough of Queens, Trump graduated from the University of Pennsylvania in 1968 with a bachelor's degree in economics.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.519396</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He became the president of his family's real estate business in 1971, renamed it the Trump Organization, and began acquiring and building skyscrapers, hotels, casinos, and golf courses.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583945</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He launched side ventures, many licensing the Trump name, and filed for six business bankruptcies in the 1990s and 2000s.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.565659</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17837</th>\n",
       "      <td>Macmillan, 2003.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476183</td>\n",
       "      <td>War on drugs</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17838</th>\n",
       "      <td>Douglas Valentine, The Strength of the Wolf: The Secret History of America's War on Drugs.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.643117</td>\n",
       "      <td>War on drugs</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17839</th>\n",
       "      <td>New York: Verso, 2004.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.588464</td>\n",
       "      <td>War on drugs</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17840</th>\n",
       "      <td>Government and NGO reports National Drug Threat Assessment 2009 from the United States Department of Justice War On Drugs: Legislation in the 108th Congress and Related Developments, a 2003 report from the Congressional Research Service via the State Department website The Report of the Canadian Government Commission of Inquiry into the Non-Medical Use of Drugs – 1972 Drug Enforcement Administration (2017), Drugs of abuse: A DEA resource guide (PDF) (2017 ed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225338</td>\n",
       "      <td>War on drugs</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17841</th>\n",
       "      <td>), Washington, D.C.: Author, archived from the original (PDF) on December 3, 2016, retrieved January 23, 2018 Revealing the missing link to Climate Justice: Drug Policy, a 2023 report from the International Coalition on Drug Policy Reform and Environmental Justice External links Narco News – news site focusing on drug war in Latin America Drug Policy Facts Major Studies of Drugs and Drug Policy Full text of major government commission reports on the drug laws from around the world over the last 100 years Historical Research on the Drug War Full text of numerous full histories of the drug war and thousands of original historical documents Cato Institute Drug Prohibition Research</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.308664</td>\n",
       "      <td>War on drugs</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17842 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        combined_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who is the 47th president of the United States.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                A member of the Republican Party, he served as the 45th president from 2017 to 2021.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Born into a wealthy family in the New York City borough of Queens, Trump graduated from the University of Pennsylvania in 1968 with a bachelor's degree in economics.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           He became the president of his family's real estate business in 1971, renamed it the Trump Organization, and began acquiring and building skyscrapers, hotels, casinos, and golf courses.   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           He launched side ventures, many licensing the Trump name, and filed for six business bankruptcies in the 1990s and 2000s.   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "17837                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Macmillan, 2003.   \n",
       "17838                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Douglas Valentine, The Strength of the Wolf: The Secret History of America's War on Drugs.   \n",
       "17839                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          New York: Verso, 2004.   \n",
       "17840                                                                                                                                                                                                                                 Government and NGO reports National Drug Threat Assessment 2009 from the United States Department of Justice War On Drugs: Legislation in the 108th Congress and Related Developments, a 2003 report from the Congressional Research Service via the State Department website The Report of the Canadian Government Commission of Inquiry into the Non-Medical Use of Drugs – 1972 Drug Enforcement Administration (2017), Drugs of abuse: A DEA resource guide (PDF) (2017 ed.   \n",
       "17841  ), Washington, D.C.: Author, archived from the original (PDF) on December 3, 2016, retrieved January 23, 2018 Revealing the missing link to Climate Justice: Drug Policy, a 2023 report from the International Coalition on Drug Policy Reform and Environmental Justice External links Narco News – news site focusing on drug war in Latin America Drug Policy Facts Major Studies of Drugs and Drug Policy Full text of major government commission reports on the drug laws from around the world over the last 100 years Historical Research on the Drug War Full text of numerous full histories of the drug war and thousands of original historical documents Cato Institute Drug Prohibition Research   \n",
       "\n",
       "       lexicon_match_count  bias_prediction  bias_probability article_title  \\\n",
       "0                        0                1          0.605232  Donald Trump   \n",
       "1                        0                1          0.521672  Donald Trump   \n",
       "2                        0                1          0.519396  Donald Trump   \n",
       "3                        0                1          0.583945  Donald Trump   \n",
       "4                        0                1          0.565659  Donald Trump   \n",
       "...                    ...              ...               ...           ...   \n",
       "17837                    0                0          0.476183  War on drugs   \n",
       "17838                    0                1          0.643117  War on drugs   \n",
       "17839                    0                1          0.588464  War on drugs   \n",
       "17840                    0                0          0.225338  War on drugs   \n",
       "17841                    0                0          0.308664  War on drugs   \n",
       "\n",
       "       sentence_index  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   3  \n",
       "4                   4  \n",
       "...               ...  \n",
       "17837             612  \n",
       "17838             613  \n",
       "17839             614  \n",
       "17840             615  \n",
       "17841             616  \n",
       "\n",
       "[17842 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_sentence_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf790b16-f4bf-43bd-8c8c-7cae50e21ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lexicon_match_count\n",
       "0    16467\n",
       "1     1128\n",
       "2      201\n",
       "3       35\n",
       "5        4\n",
       "4        4\n",
       "7        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_sentence_dataset['lexicon_match_count'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400275c-4318-4397-b619-c62b907ebf2f",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "The lexicon_match_count was `0` for **92%** of the sentences, but that is better than 100%. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04c37273-7d29-471d-a50b-6a2761bca87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_articles(titles, model):\n",
    "    summaries = []\n",
    "\n",
    "    for title in titles:\n",
    "        try:\n",
    "            result = predict_bias_from_article(title, model)\n",
    "            summaries.append({\n",
    "                'title': title,\n",
    "                'bias_score': result['bias_score'],\n",
    "                'biased_sentences': result['biased_sentences'],\n",
    "                'total_sentences': result['total_sentences']\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"error: {title} — {e}\")\n",
    "\n",
    "    return pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58511125-eea6-4aaf-84fa-da160c9b9014",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "This function takes in a list of Wikipedia article titles and runs **bias prediction** on every article.\n",
    "\n",
    "For each title:\n",
    "- It fetches the article and produces a bias score by aggregating sentence-level bias predictions.\n",
    "- It returns a dataset with article titles, bias scores, the number of biased sentences, and the number of total sentences.\n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fb4fa2c-6d9d-444a-ab7c-59418458e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_article_dataset = summarize_articles(topics, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e60edf50-611e-4bf3-8b0d-0eea18cb4c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>bias_score</th>\n",
       "      <th>biased_sentences</th>\n",
       "      <th>total_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Antifa</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Islamophobia</td>\n",
       "      <td>0.734</td>\n",
       "      <td>251</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gender identity</td>\n",
       "      <td>0.632</td>\n",
       "      <td>141</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fox News</td>\n",
       "      <td>0.581</td>\n",
       "      <td>351</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The New York Times</td>\n",
       "      <td>0.568</td>\n",
       "      <td>234</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>0.562</td>\n",
       "      <td>144</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pro-life</td>\n",
       "      <td>0.541</td>\n",
       "      <td>40</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Critical race theory</td>\n",
       "      <td>0.540</td>\n",
       "      <td>150</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Creationism</td>\n",
       "      <td>0.522</td>\n",
       "      <td>152</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tea Party movement</td>\n",
       "      <td>0.499</td>\n",
       "      <td>194</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QAnon</td>\n",
       "      <td>0.496</td>\n",
       "      <td>341</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Misinformation</td>\n",
       "      <td>0.455</td>\n",
       "      <td>205</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Evangelicalism</td>\n",
       "      <td>0.453</td>\n",
       "      <td>222</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>0.452</td>\n",
       "      <td>252</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MSNBC</td>\n",
       "      <td>0.439</td>\n",
       "      <td>136</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Christian nationalism</td>\n",
       "      <td>0.427</td>\n",
       "      <td>50</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.397</td>\n",
       "      <td>79</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pro-choice</td>\n",
       "      <td>0.368</td>\n",
       "      <td>84</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Taliban</td>\n",
       "      <td>0.367</td>\n",
       "      <td>199</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Religious freedom in the United States</td>\n",
       "      <td>0.357</td>\n",
       "      <td>114</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Flat Earth</td>\n",
       "      <td>0.346</td>\n",
       "      <td>75</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Immigration to the United States</td>\n",
       "      <td>0.333</td>\n",
       "      <td>183</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Second Amendment</td>\n",
       "      <td>0.326</td>\n",
       "      <td>203</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Abortion in the United States</td>\n",
       "      <td>0.316</td>\n",
       "      <td>174</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Transgender rights</td>\n",
       "      <td>0.314</td>\n",
       "      <td>93</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Stop and frisk</td>\n",
       "      <td>0.306</td>\n",
       "      <td>59</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bernie Sanders</td>\n",
       "      <td>0.289</td>\n",
       "      <td>187</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Vaccine hesitancy</td>\n",
       "      <td>0.275</td>\n",
       "      <td>171</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>0.266</td>\n",
       "      <td>138</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>War on drugs</td>\n",
       "      <td>0.266</td>\n",
       "      <td>164</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Border wall</td>\n",
       "      <td>0.265</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Israeli-Palestinian conflict</td>\n",
       "      <td>0.257</td>\n",
       "      <td>134</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>0.254</td>\n",
       "      <td>173</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hamas</td>\n",
       "      <td>0.253</td>\n",
       "      <td>153</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Same-sex marriage</td>\n",
       "      <td>0.252</td>\n",
       "      <td>36</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Climate change</td>\n",
       "      <td>0.243</td>\n",
       "      <td>118</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ukraine war</td>\n",
       "      <td>0.221</td>\n",
       "      <td>17</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kamala Harris</td>\n",
       "      <td>0.215</td>\n",
       "      <td>67</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LGBT adoption</td>\n",
       "      <td>0.211</td>\n",
       "      <td>30</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Police brutality</td>\n",
       "      <td>0.206</td>\n",
       "      <td>28</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Black Lives Matter</td>\n",
       "      <td>0.195</td>\n",
       "      <td>130</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ron DeSantis</td>\n",
       "      <td>0.192</td>\n",
       "      <td>58</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Affirmative action</td>\n",
       "      <td>0.167</td>\n",
       "      <td>59</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>COVID-19 pandemic</td>\n",
       "      <td>0.160</td>\n",
       "      <td>99</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gun control</td>\n",
       "      <td>0.146</td>\n",
       "      <td>27</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Russian invasion of Ukraine</td>\n",
       "      <td>0.132</td>\n",
       "      <td>95</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NATO</td>\n",
       "      <td>0.122</td>\n",
       "      <td>30</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  bias_score  biased_sentences  \\\n",
       "6                                   Antifa       1.000                 1   \n",
       "34                            Islamophobia       0.734               251   \n",
       "19                         Gender identity       0.632               141   \n",
       "22                                Fox News       0.581               351   \n",
       "26                      The New York Times       0.568               234   \n",
       "25                          Breitbart News       0.562               144   \n",
       "9                                 Pro-life       0.541                40   \n",
       "20                    Critical race theory       0.540               150   \n",
       "42                             Creationism       0.522               152   \n",
       "7                       Tea Party movement       0.499               194   \n",
       "8                                    QAnon       0.496               341   \n",
       "40                          Misinformation       0.455               205   \n",
       "33                          Evangelicalism       0.453               222   \n",
       "0                             Donald Trump       0.452               252   \n",
       "23                                   MSNBC       0.439               136   \n",
       "35                   Christian nationalism       0.427                50   \n",
       "24                                     CNN       0.397                79   \n",
       "10                              Pro-choice       0.368                84   \n",
       "32                                 Taliban       0.367               199   \n",
       "36  Religious freedom in the United States       0.357               114   \n",
       "41                              Flat Earth       0.346                75   \n",
       "14        Immigration to the United States       0.333               183   \n",
       "13                        Second Amendment       0.326               203   \n",
       "11           Abortion in the United States       0.316               174   \n",
       "16                      Transgender rights       0.314                93   \n",
       "45                          Stop and frisk       0.306                59   \n",
       "5                           Bernie Sanders       0.289               187   \n",
       "39                       Vaccine hesitancy       0.275               171   \n",
       "3                             Barack Obama       0.266               138   \n",
       "46                            War on drugs       0.266               164   \n",
       "15                             Border wall       0.265                13   \n",
       "27            Israeli-Palestinian conflict       0.257               134   \n",
       "1                                Joe Biden       0.254               173   \n",
       "28                                   Hamas       0.253               153   \n",
       "18                       Same-sex marriage       0.252                36   \n",
       "37                          Climate change       0.243               118   \n",
       "29                             Ukraine war       0.221                17   \n",
       "2                            Kamala Harris       0.215                67   \n",
       "17                           LGBT adoption       0.211                30   \n",
       "43                        Police brutality       0.206                28   \n",
       "44                      Black Lives Matter       0.195               130   \n",
       "4                             Ron DeSantis       0.192                58   \n",
       "21                      Affirmative action       0.167                59   \n",
       "38                       COVID-19 pandemic       0.160                99   \n",
       "12                             Gun control       0.146                27   \n",
       "30             Russian invasion of Ukraine       0.132                95   \n",
       "31                                    NATO       0.122                30   \n",
       "\n",
       "    total_sentences  \n",
       "6                 1  \n",
       "34              342  \n",
       "19              223  \n",
       "22              604  \n",
       "26              412  \n",
       "25              256  \n",
       "9                74  \n",
       "20              278  \n",
       "42              291  \n",
       "7               389  \n",
       "8               688  \n",
       "40              451  \n",
       "33              490  \n",
       "0               557  \n",
       "23              310  \n",
       "35              117  \n",
       "24              199  \n",
       "10              228  \n",
       "32              542  \n",
       "36              319  \n",
       "41              217  \n",
       "14              549  \n",
       "13              623  \n",
       "11              551  \n",
       "16              296  \n",
       "45              193  \n",
       "5               647  \n",
       "39              621  \n",
       "3               518  \n",
       "46              617  \n",
       "15               49  \n",
       "27              521  \n",
       "1               681  \n",
       "28              604  \n",
       "18              143  \n",
       "37              486  \n",
       "29               77  \n",
       "2               311  \n",
       "17              142  \n",
       "43              136  \n",
       "44              665  \n",
       "4               302  \n",
       "21              353  \n",
       "38              619  \n",
       "12              185  \n",
       "30              720  \n",
       "31              245  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_article_dataset.sort_values(by='bias_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1843e5-b582-4879-a9ee-43b5867d2156",
   "metadata": {},
   "source": [
    "────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "**Randy's Update**\n",
    "\n",
    "The 47 articles in the topics list have a wide range of bias scores between **0.12 and 1.0**. The top score has only one sentence, so it might not be a good example, but the next two highest scores are greater than 0.6, which is still quite high. \n",
    "\n",
    "────────────────────────────────────────────────────────────────────────────"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edb0ba7-1dca-42d5-9d8b-d353093e7f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
